{
  "alternatePhrases": [
    "convolve",
    "fold",
    "convolved",
    "folded"
  ],
  "definition": "#### Introduction\n\nThe *convolution* of two functions $f,g : \\Bbb{R} \\rightarrow \\Bbb{R}$\nis the function\n\n$$(f \\ast g)(u) = \\int_{-\\infty}^\\infty f(x)g(u-x)dx.$$\n\n$(f \\ast g)(u)$ is the sum of all the terms $f(x)g(y)$ where\n$x + y = u$. Such sums occur when investigating sums of random\nvariables, and discrete versions appear in the coefficients of products\nof polynomials and power series. Convolution is an important tool in\ndata processing, in particular in digital signal and image processing.\nWe will first define the concept in various general settings, discuss\nits properties and then list several convolutions of probability\ndistributions.\n\n#### Definitions\n\nIf $G$ is a with Haar measure $\\mu$ and $f$ and $g$ are measurable\nfunctions on $G$, we define the convolution\n\n$$(f \\ast g)(u) := \\int_G f(x)g(u - x)d\\mu(x)$$\n\nwhenever the right hand side integral exists (this is for instance the\ncase if $f\\in L^p(G,\\mu)$, $g\\in L^q(G,\\mu)$ and $1/p + 1/q = 1$).\n\nThe case $G = \\Bbb{R}^n$ is the most important one, but $G=\\Bbb{Z}$ is\nalso useful, since it recovers the convolution of sequences which occurs\nwhen computing the coefficients of a product of polynomials or power\nseries. The case $G=\\Bbb{Z}_n$ yields the so-called cyclic convolution\nwhich is often discussed in connection with the discrete Fourier\ntransform. Based on this definition one also obtains the\n\nThe (Dirichlet) convolution of multiplicative functions considered in\nnumber theory does not quite fit the above definition, since there the\nfunctions are defined on a commutative monoid (the natural numbers under\nmultiplication) rather than on an abelian group.\n\nIf $X$ and $Y$ are independent random variables with probability\ndensities $f_X$ and $f_Y$ respectively, and if $X+Y$ has a probability\ndensity, then this density is given by the convolution $f_X \\ast f_Y$.\nThis motivates the following definition: for probability distributions\n$P$ and $Q$ on $\\Bbb{R}^n$, the convolution $P \\ast Q$ is the\nprobability distribution on $\\Bbb{R}^n$ given by\n\n$$(P \\ast Q)(A) := (P \\times Q)\\big( \\{ (x,y) \\mid x+y\\in A \\}\\big) = \\int_{\\mathbb{R}^n} Q(A-x) \\, dP(x)$$\n\nfor every Borel set $A$. The last equation is the result of Fubini\u2019s\ntheorem.\n\nThe convolution of two distributions $u$ and $v$ on $\\Bbb{R}^n$ is\ndefined by\n\n$$(u \\ast v)(\\phi) = u( \\psi)$$\n\nfor any test function $\\phi$ for $v$, assuming that\n$\\psi(t) := v(\\phi(\\cdot + t))$ is a suitable test function for $u$.\n\n#### Properties\n\nThe convolution operation, when defined, is commutative, associative and\ndistributive with respect to addition. For any $f$ we have\n$$f \\ast \\delta = f,$$ where $\\delta$ is the Dirac delta distribution.\nThe Fourier transform $F$ converts the convolution of two functions into\ntheir pointwise multiplication: $$F(f \\ast g) = F(f) \\cdot F(g),$$ which\nprovides a great simplification in the computation of convolution.\nBecause of the availability of the Fast Fourier Transform and its\ninverse, this latter relation is often used to quickly compute discrete\nconvolutions, and in fact the fastest known algorithms for the\nmultiplication of numbers and polynomials are based on this idea.\n\n#### Some convolutions of probability distributions\n\n-   The convolution of two independent normal distributions with zero\n    mean and variances $\\sigma_1^2$ and $\\sigma_2^2$ is a normal\n    distribution with zero mean and variance\n    $\\sigma^2 = \\sigma_1^2 + \\sigma_2^2$.\n\n-   The convolution of two $\\chi^2$ distributions with $f_1$ and $f_2$\n    degrees of freedom is a $\\chi^2$ distribution with $f_1 + f_2$\n    degrees of freedom.\n\n-   The convolution of two Poisson distributions with parameters\n    $\\lambda_1$ and $\\lambda_2$ is a Poisson distribution with parameter\n    $\\lambda = \\lambda_1 + \\lambda_2$.\n\n-   The convolution of an exponential and a normal distribution is\n    approximated by another exponential distribution. If the original\n    exponential distribution has density\n\n    $$f(x)=\\frac{e^{-x/\\tau}}{\\tau} \\;\\;\\; (x \\ge 0) \\text{ or } f(x)=0 \\;\\;\\; (x < 0) ,$$\n\n    and the normal distribution has zero mean and variance $\\sigma^2$,\n    then for $u \\gg \\sigma$ the probability density of the sum is\n\n    $$f(u) \\approx \\frac{e^{-u/\\tau + \\sigma^2/(2\\tau^2)}}{\\sigma \\tau \\sqrt{2\\pi}}$$\n\n    In a semi-logarithmic diagram where $\\log(f_X(x))$ is plotted versus\n    $x$ and $\\log (f(u))$ versus $u$, the latter lies by the amount\n    $\\sigma^2/(2\\tau^2)$ higher than the former but both are represented\n    by parallel straight lines, the slope of which is determined by the\n    parameter $\\tau$.\n\n-   The convolution of a uniform and a normal distribution results in a\n    quasi-uniform distribution smeared out at its edges. If the original\n    distribution is uniform in the region $a \\le x < b$ and vanishes\n    elsewhere and the normal distribution has zero mean and variance\n    $\\sigma^2$, the probability density of the sum is\n\n    $$f(u) = \\frac{\\psi_0((u-a)/\\sigma)-\\psi_0((u-b)/\\sigma)}{b-a},$$\n\n    where\n\n    $$\\psi_0(x) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^x e^{-t^2/2} dt$$\n\n    is the distribution function of the standard normal distribution.\n    For $\\sigma \\rightarrow 0$, the function $f(u)$ vanishes for $u<a$\n    and $u>b$ and is equal to $1/(b-a)$ in between. For finite $\\sigma$\n    the sharp steps at $a$ and $b$ are rounded off over a width of the\n    order $2\\sigma$.\n\n#### References\n\n-   Adapted with permission from The Data Analysis Briefbook ()",
  "language": "INFORMAL",
  "phrase": "Convolution",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/Convolution"
    }
  ],
  "indexable": true
}