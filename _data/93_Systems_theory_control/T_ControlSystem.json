{
  "alternatePhrases": [],
  "definition": "The sole objective of control system is to generate feasible inputs to\nthe plant (e.g. dynamic systems) such that it will operate as it\nintended to under a wide range of operating conditions.\n\nExamples of control systems: Cruise control, auto pilot, rice cooker.\n\nFor a general finite dimensional dynamic system in its ODE form,\n\n$$\\begin{aligned}\n  \\label{eq:eq1}\n  \\dot{x} &= f(x(t),t) + g(x(t), u(t), t), \\\\\n  y &= h(x(t),t), \\nonumber\\end{aligned}$$\n\nwhere $x \\in \\mathbb{R}^n$ is the state, $y \\in \\mathbb{R}^l$ is the\noutput and $u \\in \\mathbb{R}^m$ is the control input of the system. In\nthe control literature, equation \\[eq:eq1\\] is general referred as the\nplant, where the function $f: \\mathbb{R}^n \\times\n\\mathbb{R} \\rightarrow \\mathbb{R}^n$ governs the system dynamics, $g:\n\\mathbb{R}^m \\times \\mathbb{R}^n \\times \\mathbb{R} \\rightarrow\n\\mathbb{R}^n$ determines how the input (control signals) influence the\nstate $x$ via [*actuators*]{} (e.g. gas turbine) and\n$h: \\mathbb{R}^n \\times \\mathbb{R} \\rightarrow \\mathbb{R}^l$ determines\nhow the state generates the output signal. If $m$ is equal to $n$, the\nplant is [*fully actuated*]{}. If $m < n$ then the plant is [*under\nactuated*]{} and otherwise the plant is [*over actuated*]{}. For a plant\nthat is not explicitly dependent in time $t$, such system is called a\n[*Autonomous*]{} system. The main differece between a control system and\na general dynamic system is the additional signal $u(t)$.\n\nFor example, to control an airplane, the control system has to control\nthe [*thrust*]{}, [*flaps*]{}, [*aileron*]{} and [*rudder*]{}, which\nthey are the control signals of the system $u$. Those control input\ninfluence the system state $x$ such as [*speed*]{} (with thrust),\n[*attitude*]{} and [*orientation*]{} (with flaps, aileron and rudder).\nTo physically alter the state of the airplane, actuators such as gas\nturbines are needed, which are controlled by the control signals $u$.\n\nThe control signal $u$ can be generated in a [*closed-loop*]{} fashion\nor [*open-loop*]{} fashion. An open-loop control system generates $u$\nwith the user, or operator supplied reference state $x_{d}$ or output\n$y_{d}$ only; meanwhile closed-loop control system uses both reference\nand [*feedback*]{} signals that are usually measured from [*sensors*]{}.\nIn the airplane attitude control example, the desired attitude is\nusually represented in roll-pitch-yaw angle representation, and these\nsignals are measurable by attaching sensors to the flaps, aileron and\nrudder. In engineering practice, only closed-loop control systems should\nbe used, since open-loop systems are not [*robust*]{} against\nuncertainties, modeling errors and measurement errors.\n\nIf a closed-loop control system is based on state feedback, such contol\nsystem is called a [*state-feedback*]{} control system. By the same\ntoken, a [*output-feedback*]{} control system is based on output\nfeedback only. Notice that output signals are available for feedback by\ndefinition, however in reality not all the states are mesurable. If a\nstate-feedback control system with all the states available for\nfeedback, it is called a [*full-state feedback*]{} system and otherwise\nis call [*partial-state feedback*]{} system, which usually requires a\n[*state observer*]{} (e.g. Kalman filter) to estimate the unavailable\nstates.\n\nTo illustrate the simple concept of control systems, we will use a\nsimple example. A truck driver is required to travel 1000 Km in 10\nhours. To relive the stress on the driver\u2019s heel, he has placed a stick\nto the gas paddle so the car travels at $\\u{100Km/h}$. Under perfect\nconditions, the driver will reach the destination in the allocated time.\nHowever, a certain section of the road is up-hill, so the truck slowed\ndown by a considerable amount and will not arrive it\u2019s destination in\ntime. To remedy this problem, the driver \u2019implemented\u2019 a simple solution\nusing the speed-o-meter such that the gas paddle position $p_{set}$ of\nthe truck is now depends on the current speed $v_{current}$ of the\ntruck, $p_{set} = -K (v_{current} - \\u{100Km/h})$, where $K$ is just an\nadjustable parameter. So if the truck is running too slow (e.g.\nup-hill), $p_{set}$ will be positive (more gas to the engine) hence\nspeed will increase to maintain the desired speed, so vice-versa for the\ndown-hill case.\n\nIn this example, we have outlined all the major components of a typical\ncontrol system:\n\n-   Actuator: engine,\n\n-   Sensor: speed-o-meter,\n\n-   Plant: truck,\n\n-   Control input: gas paddle,\n\n-   Control objective: 1000 Km in 10 hrs,\n\n-   Control law: $p_{set} = -K (v_{current} - 100Km/h)$,\n\nThe science aspect of control systems is the study of design, synthesis\nand analysis of control systems using mathematical concepts, and the\nengineering aspect of controls systems is to implement, construct and\nadjust the control system according to real-life situation and\nlimitations.",
  "language": "INFORMAL",
  "phrase": "Control System",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/ControlSystem"
    }
  ],
  "indexable": true
}