{
  "alternatePhrases": [],
  "definition": "Association schemes were introduced by statisticians in the 1950\u2019s to\nanalyze designs of statistical experiments. Today, association schemes\nare useful not only in experimental designs, but in other areas of\nmathematics such as combinatorics (coding theory) and group theory\n(permutation groups).\n\nThere are several equivalent ways to define an association schemes.\nThree useful ones are illustrated here:\n\nLet $\\Omega$ be a non-empty set with $n$ elements, and $s$ a positive\ninteger.\n\n**Definition 1**. An *association scheme* $\\mathscr{Q}$ on $\\Omega$ is a\npartition on $\\Omega\\times \\Omega$ into sets $C_0,C_1,\\ldots, C_s$\ncalled *associate classes*, such that\n\n-   each $C_i$ is a symmetric relation on $\\Omega$, and $C_0$ in\n    particular is the diagonal relation,\n\n-   for $i,j,k\\in \\lbrace 0,1,\\ldots,s\\rbrace$, there is an integer\n    $p_{ij}^k$ such that, for any $(a,b)\\in C_k$,\n    $$|\\lbrace c \\in \\Omega \\mid (a,c)\\in C_i \\mbox{ and } (c,b)\\in C_j \\rbrace|=p_{ij}^k.$$\n\nIf we write $C(a,b;i,j)$ for the set\n$\\lbrace c \\in \\Omega \\mid (a,c)\\in C_i \\mbox{ and } (c,b)\\in C_j \\rbrace$,\nthen the second condition says that for any $(a,b)\\in C_k$, the value\n$|C(a,b;i,j)|$ is a constant, depending only on $i,j$ and $k$, and not\non the particular elements of $C_k$. This implies that, for any\n$i,j\\in \\lbrace 0,1,\\ldots, n\\rbrace$, the relation $C_i\\circ C_j$ is a\nunion of (some of) the $C_k$\u2019s.\n\nThe definition above can be restated in graph theoretic terminology.\nFirst, think of $\\Omega$ is a set of vertices, and two-element subsets\nof $\\Omega$ are edges. The complete graph on $\\Omega$ is just the set of\nall two-element subsets of $\\Omega$. We may color the edges of the\ngraph. Say there are colors labeled $1$ through $s$. For each color $i$,\nlet $C_i$ be the set of edges with color $i$. Then each $C_i$ is just a\nsymmetric relation on $\\Omega$, and that all the $C_i$\u2019s, together with\nthe diagonal relation, partition the set $\\Omega\\times\\Omega$. This is\nbasically the first condition of the definition above. In this regard,\nwe can redefine an association scheme graph theoretically, as follows:\n\n**Definition 2**. An *association scheme* $\\mathscr{Q}$ is a surjective\ncoloring on the edge set of a complete graph whose vertex set is\n$\\Omega$, by a set of $s$ colors (numbered $1$ through $s$), such that\n\n> for any $i,j,k\\in \\lbrace 1,\\ldots,s\\rbrace$, there is an integer\n> $p_{ij}^k$ such that if $\\mathscr{Q}(a,b)=k$ (the edge\n> $\\lbrace a,b\\rbrace$ has color $k$), then\n> $$|\\lbrace c \\in \\Omega \\mid \\mathscr{Q}(a,c)=i \\mbox{ and } \\mathscr{Q}(c,b)=j \\rbrace|=p_{ij}^k.$$\n\nIn words, the definition says that, for any color $k$, and any given\nedge $e$ with color $k$, the number of triangles (a triangle in a graph\nis a cycle consisting of three edges) with $e$ as an edge, and two other\nedges with colors $i,j$ respectively, is $p_{ij}^k$.\n\nThe first definition can also be viewed in terms of matrices, and\nadjacency matrices more specifically. Given a finite set $\\Omega$, a\nbinary relation $R$ on $\\Omega$ naturally corresponds to matrix $A$\ncalled the adjacency matrix of $R$. Entry $(i,j)$ is $1$ if the $i$-th\nelement and the $j$-th element are related by $R$, and $0$ otherwise. If\n$R$ is reflexive, then $A$ has all $1$\u2019s in its diagonal, and if $R$ is\nsymmetric, then so is $A$. Also, it is easy to see that the composition\nof two binary relations is the same as the product of their\ncorresponding adjacency matrices. Then the comment in the paragraph\nafter the first definition is the same as saying that the adjacency\nmatrix of $C_i\\circ C_j$ is a linear combination of the adjacency\nmatrices of $C_0,C_1,\\ldots, C_s$. This gives us the third definition\nbelow:\n\n**Definition 3**. An *association scheme* is a finite set $\\mathscr{Q}$\nof $n\\times n$ non-zero matrices $A_0, A_1,\\ldots,A_s$ whose entries are\n$0$\u2019s and $1$\u2019s, such that\n\n-   each $A_i$ is a symmetric matrix, with $A_0=I_n$, the identity\n    matrix,\n\n-   $A_0+A_1+\\cdots + A_s = J_n$, the matrix whose entries are all\n    $1$\u2019s, and\n\n-   for any $i,j\\in \\lbrace 0,\\ldots, s\\rbrace$, $A_iA_j$ is a linear\n    combination of $A_0,A_1,\\ldots, A_s$.\n\nBy the definitions of the matrices $A_i$ and the second condition, for\nevery pair $(r,s)$, exactly one of the $s+1$ matrices has $1$ in cell\n$(r,s)$, and all others have $0$ in the corresponding cell. As a result,\nthe $s+1$ matrices are linearly independent.\n\nAlso, in view of the discussion above, it is easy to see that\n$$A_iA_j=p_{ij}^0 A_0 + p_{ij}^1 A_1 + \\cdots + p_{ij}^s A_s.$$\n\n**Some terminology**. $s$ is called the *rank* of the association scheme\n$\\mathscr{Q}$. Any $a\\in \\Omega$, an element $c\\in \\mathscr{Q}$ is said\nto be an *$i$-associate* of $a$ if $(a,c)\\in C_i$. For each\n$a\\in \\Omega$, define:\n$$C_i(a):=\\lbrace c\\in \\Omega\\mid (a,c)\\in C_i\\rbrace.$$ So $C_i(a)$ is\nthe set of all $i$-associates of $a$. Then\n$$|C_i(a)\\cap C_j(b)|=p_{ij}^k,\\mbox{ whenever }(a,b)\\in C_k,$$ and\nbecause of the above equation, each $p_{ij}^k$ is called an\n*intersection number* of $\\mathscr{Q}$. For each $i$, the intersection\nnumber $p_{ii}^0$ is called the *valency* of $C_i$, denoted by $a_i$.\n\nSome basic properties of the intersection numbers:\n\n-   $p_{ij}^k=p_{ji}^k$\n\n-   $$p_{i0}^k = \\left\\{\n    \\begin{array}{ll}\n    1 & \\textrm{if }i=k\\\\\n    0 & \\textrm{otherwise.}\n    \\end{array}\n    \\right.$$\n\n-   $|C_i(c)|=p_{ii}^0=a_i$ for all $c\\in \\Omega$.\n\n[7]{} R. A. Bailey, [*Association Schemes, Designed Experiments, Algebra\nand Combinatorics*]{}, Cambridge University Press (2004)",
  "language": "INFORMAL",
  "phrase": "Association Scheme",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/AssociationScheme"
    }
  ],
  "indexable": true
}