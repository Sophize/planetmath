{
  "alternatePhrases": [
    "in-situ sorting algorithm"
  ],
  "definition": "A sorting algorithm is said to be *in-place* if it requires very little\nadditional space besides the initial array holding the elements that are\nto be sorted. Normally \u201cvery little\u201d is taken to mean that for sorting\n$n$ elements, $O(\\log n)$ extra space is required.[^1] This is\nreasonable because in a purely mathematical analysis of the algorithms,\n*any* sorting algorithm that operates on a contiguous array requires\n$O(\\log n)$ extra space, since this is the number of bite required to\nrepresent an index into the array. Normally one ignores this as in most\nalgorithms one treats integers as a data type requiring constant space\nand constant time for basic operations. An exception are number\ntheoretic algorithms often encountered in .\n\nOf course, the efficiency of any algorithm will depend on how the data\nis stored; usually, the elementary discussion of sorting algorithms\nfocuses on sorting elements stored in a contiguous array (which has\nconstant-time access and swap operations but takes a long time to do\nshifts). In this context, Heapsort is an in-place sorting algorithm,\nsince it requires constant additional space. Quicksort is also\nconsidered in-place, although it requires an amount of extra space\nlogarithmic in the size of the array. Most implementations of Quicksort\nare recursive, and each recursive call needs to store some local\nvariables on the stack; the depth of the recursion is usually\n$O(\\log n)$, but can be $O(n)$ in degenerate cases. If you try to\nconvert Quicksort to a non-recursive algorithm, you will find that it is\nnecessary to store some intermediatde indexes on a stack, which usually\ngrows up to size $O(\\log n)$ but may grow up to size $O(n)$. Mergesort\nis a sorting algorithm with running time $O(n\\log n)$ which is not\nin-place when dealing with arrays.\n\nOn the other hand, if one is sorting linked lists, looking up a general\nelement by index requires $O(n)$ steps, so Quicksort and Heapsort need\nto be drastically modified to run in even $O(n^2)$; this is not a\nnatural context to use these algorithms. Mergesort, on the other hand,\nretains its $O(n\\log n)$ time complexity and requires only $O(\\log n)$\nextra space.\n\nIn-place sorting is often useful when dealing with truly enormous data\nsets, where $O(n)$ extra space is truly difficult to work with. In-place\nsorting algorithms may or may not have better locality of reference than\nother sorting algorithms. Truly enormous data sets are usually stored on\nmedia where random access of data is very expensive but extra storage\nspace is realtively inexpensive (such as disks); in these cases, whether\nan algorithm is in-place is less relevant. In fact, even when dealing\nwith data stored as arrays Mergesort is much more efficient for\ndisk-based sorting than the other algorithms because of its better\nlocality of reference.\n\nIt should be pointed out in any analysis of the standard sorting\nalgorithms that they are based on an assumption that is almost never\ntrue: they assume that the only operation possible on keys is\ncomparison. Sorting methods taking advantage of the structure of keys\n(say, they are strings) can be much faster both asymptotically and in\npractice; they are generally not in-place, but the extra space is often\nworth the time advantage.\n\n[^1]: In fact, one should really allow any polynomial in $\\log n$ in\n    order for to qualify. So perhaps the condition should be expressed\n    as $O(n^\\epsilon)$ for every $\\epsilon>0$. These are distinctions in\n    complexity that are almost always ignored since they are dwarfed in\n    practical problems by implementation differences.",
  "language": "INFORMAL",
  "phrase": "In-Place Sorting Algorithm",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/InplaceSortingAlgorithm"
    }
  ],
  "indexable": true
}