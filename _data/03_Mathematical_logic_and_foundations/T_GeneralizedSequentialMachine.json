{
  "alternatePhrases": [
    "gsm",
    "deterministic generalized sequential machine"
  ],
  "definition": "### Definition {#definition .unnumbered}\n\nGeneralized sequential machines are generalizations of finite state\nsequential machines. In a finite state machine\n$M=(S,\\Sigma,\\Delta,\\delta,\\lambda)$, the next-state ($\\delta$) and\noutput ($\\lambda$) functions work independently of one another in the\nsense that no next states affect the outputs, and vice versa: given an\ninput symbol $a$ and current state $s$, if $p,q$ are next states, and\n$c,d$ are output symbols, then all four output configurations are\npossible: $(p,c), (p,d), (q,c), (q,d)$. In addition, for a given input\nsymbol $a$, the corresponding outputs are individual symbols in the\noutput alphabet, rather than words: $\\lambda(s,a)$ is a subset of\n$\\Delta$. When these restrictions are removed, we have a generalized\nsequential machine.\n\nFormally, a *generalized sequential machine* is a quadruple\n$M=(S,\\Sigma,\\Delta,\\tau)$, such that\n\n1.  $S$ is an alphabet whose elements are called *states*,\n\n2.  $\\Sigma$ is an alphabet whose elements are called *input symbols*,\n\n3.  $\\Delta$ is an alphabet whose elements are called *output symbols*,\n    and\n\n4.  $\\tau$ is a function from $S\\times \\Sigma$ to $P(S\\times \\Delta^*)$,\n    such that $\\tau(s,a)$ is finite for all $(s,a) \\in S\\times \\Sigma$.\n    $\\tau$ is called the *transition function*.\n\nA generalized sequential machine is also called a *gsm* for short. Note\nthat a gsm $M$ becomes a finite state machine if $\\tau$ can be written\nas $(\\delta,\\lambda)$, and $\\lambda$ is a function from $S\\times \\Sigma$\nto $P(\\Delta)$. A gsm is said to be *deterministic* if each $\\tau(s,a)$\nis a singleton. So a Mealy machine is just a deterministic gsm such that\n$\\tau(s,a)$ consists of an output symbol.\n\nLike a finite state machine, the function $\\tau$ can be extended so its\nfirst component applies to sets of states, rather than individual\nstates: $$\\tau(T,a)=\\bigcup \\lbrace \\tau(s,a)\\mid s\\in T\\rbrace.$$ As\nusual, $\\tau(\\varnothing,a)=\\varnothing$.\n\nNext, we can extend $\\tau$ so $M$ can process input words rather than\ninput symbols. The key idea, like in the case of a fsm, is that the\ninput word is processed one symbol at a time from left to right. Each\ntime an input symbol is processed or consumed, a set of output\nconfigurations are produced. The states in these output configurations\nare used to process the next input symbols, and the outputs are appended\nto the right of the outputs that have already been generated. More\nprecisely,\n$$\\tau(T,ua):= \\lbrace (s,vw) \\mid (s,w)\\in \\tau(t,a)\\mbox{ for some }t\\in S\\mbox{ such that }(t,v)\\in \\tau(T,u) \\rbrace.$$\nWhen the input word is the empty word $\\lambda$, we require its output\nto be the empty word also, without changing the state, hence\n$\\tau(s,\\lambda):=\\lbrace (s,\\lambda)\\rbrace$.\n\nHere\u2019s an example. Let\n$M=(\\lbrace s,t\\rbrace, \\lbrace a,b\\rbrace,\\lbrace c,d\\rbrace, \\tau)$ be\na gsm whose transition function $\\tau$ is given by the following table\n\n   $(x,y)$              $\\tau(x,y)$\n  --------- -----------------------------------\n   $(s,a)$        $\\lbrace (t,c) \\rbrace$\n   $(s,b)$   $\\lbrace (s,cd), (s,d^2) \\rbrace$\n   $(t,a)$       $\\lbrace (t,dc) \\rbrace$\n   $(t,b)$   $\\lbrace (s,d), (s,c^2) \\rbrace$\n\nTo fine $\\tau(s,ab)$, first find $\\tau(s,a)$, which consists of a single\noutput configuration $(t,c)$ according to the table above. So $c$ will\nserve as the prefix of the output(s). The next state is now $t$, to be\napplied to the second symbol $b$ in $ab$. By the table above,\n$\\tau(t,b)$ has two output configurations: $(s,d)$ and $(s,c^2)$.\nTherefore, the final output configurations are $(s,cd)$ and $(s,c^3)$,\nwhen $c$ is appended to the left of $d$ and $c^2$. We may also apply the\nformula above: $$\\begin{aligned}\n\\tau(s,ab) &=& \\lbrace (p,vw) \\mid (p,w) \\in \\tau(q,b) \\mbox{ where }(q,v)\\in \\tau(s,a)\\rbrace \\\\ &=& \\lbrace (p,cw) \\mid (p,w) \\in \\tau(t,b) \\rbrace \\\\ &=& \\lbrace (s,cd),(s,c^3)\\rbrace.\\end{aligned}$$\n\n### Language Translation {#language-translation .unnumbered}\n\nA gsm can be used to translate languages. In other words, an input\nlanguage $L$ over $\\Sigma$ is fed into a gsm $M$ so that an output\nlanguage $M(L)$ is produced, or \u201ctranslated\u201d. This can be done by fixing\na start state $s_0$ and a set $F$ of final states, much like an\nautomaton. First, consider an input word $u$, then $\\tau(s_0,u)$ is the\nresulting set of output configurations. Define the set of outputs\ntranslated from $u$ by $M$ as:\n$$\\operatorname{GSM}_M(u):=\\lbrace v \\mid (t,v)\\in \\tau(s_0,u)\\mbox{ for some }t\\in F\\rbrace.$$\nMore generally, let $L$ be an input language (a set of inputs), define\nthe output language translated from $L$ by $M$ as:\n$$\\operatorname{GSM}_M(L):=\\lbrace v \\mid v\\in\\operatorname{GSM}(u)\\mbox{ for some }u\\in L\\rbrace.$$\nIt is clear that $\\operatorname{GSM}_M$ is a mapping from $P(\\Sigma^*)$\nto $P(\\Delta^*)$, and it is in this regard that we see $M$ as a language\ntranslator. Of course, different start states and different sets of\nfinal states produce different translations, which is the reason why a\ngsm is usually regarded as a 6-tuple $(S,\\Sigma,\\Delta,\\tau,s_0,F)$\nrather than a quadruple.\n\nGiven a set $K$ of output words, one can ask the inverse question: what\nare all the input words whose output configurations contain an output\nword in $K$? In other words, we are forming the set:\n$$\\operatorname{GSM}^{-1}_M(K):=\\lbrace u\\mid \\operatorname{GSM}_M(u)\\cap K\\ne \\varnothing \\rbrace.$$\nNote, however, that if $L=\\operatorname{GSM}^{-1}_M(K)$, then $L$ in\ngeneral does not get translated to $K$: the function\n$\\operatorname{GSM}^{-1}_M$ is not a functional inverse of\n$\\operatorname{GSM}_M$:\n$$\\operatorname{GSM}_M\\circ \\operatorname{GSM}^{-1}_M(K) \\ne K \\qquad \\mbox{and} \\qquad \\operatorname{GSM}_M^{-1}\\circ \\operatorname{GSM}_M(L) \\ne L$$\nin general.\n\n### GSM as an Acceptor {#gsm-as-an-acceptor .unnumbered}\n\nA gsm may be turned into a language acceptor in the following way: let\n$M=(S,\\Sigma,\\Delta,\\tau,s_0,F)$ be a gsm with starting state $s_0$ and\n$F$ the set of final states. Then the language\n$$L(M):=\\lbrace u\\in \\Sigma^* \\mid \\operatorname{GSM}(u)\\ne \\varnothing \\rbrace$$\nis called the language *accepted by M*. Now, given $M$, we may construct\na gsm $M'=(S,\\Sigma,\\varnothing,\\tau',s_0,F)$, such that\n$\\tau'(s,a):=\\lbrace (t,\\epsilon)\\mid (t,v)\\in \\tau(s,a)\\mbox{ for some }v\\in \\Delta^*\\rbrace$,\nwhere $\\epsilon$ denotes the empty word. It is easy to see that\n$L(M)=L(M')$. Given any $(s,a)\\in S\\times \\Sigma$, define $s\\to at$ iff\n$(t,\\epsilon)\\in \\tau'(s,a)$. From this, it is readily seen that the\nformal grammar $G=(\\Sigma \\cup S,F,P,s_0)$, where the productions in $P$\nare of the form $s\\to at$ defined earlier, generates $L(M')$. As a\nresult, every language accepted by a gsm is regular. It is not hard to\nsee that the converse is also true: every regular language is accepted\nby some gsm.\n\n### GSM Mappings {#gsm-mappings .unnumbered}\n\nThe gsm mapping of a gsm $M$ is the function\n$\\operatorname{GSM}_M: P(\\Sigma^*)\\to P(\\Delta^*)$ defined earlier. A\nGSM mapping is a function $\\operatorname{GSM}_M$ for some gsm $M$. An\ninverse GSM mapping is defined similarly. A GSM mapping is said to be\n$\\lambda$-free if $(t,\\epsilon)\\notin \\tau(s,a)$ for any\n$(s,a)\\in S\\times \\Sigma$.\n\n**Examples**\n\n-   Any language homomorphism is a gsm mapping. Given a homomorphism\n    $h:\\Sigma\\to \\Delta^*$, define $M=(S,\\Sigma,\\Delta,\\tau,s_0,F)$ such\n    that $S=F=\\lbrace s_0\\rbrace$ and\n    $\\tau(s_0,a)=\\lbrace (s_0, h(a))\\rbrace$. Then $M$ is a gsm with\n    $\\operatorname{GSM}_M=h$. Similarly, any inverse homomorphism is an\n    inverse gsm mapping.\n\n-   The mapping $L\\mapsto L\\cap R$, where $R$ is a regular language, is\n    a gsm mapping. To see this, let $G$ be a grammar generating $R$\n    consisting of productions of the form $A\\to aB$ or the form\n    $A\\to \\lambda$. Define $M=(S,\\Sigma,\\Sigma,\\tau,s_0,F)$ as follows:\n    $S$ consists of the non-terminals of $G$ as well as a new symbol\n    $s$, $s_0$ is the starting symbol for $G$, and $F=\\lbrace s\\rbrace$.\n    Next, set $\\tau(A,a)=(B,a)$ iff $A\\to aB$, and $\\tau(A,a)=(s,a)$ iff\n    $A\\to \\lambda$. Then, for any word $u$, it is easy to see that\n    $\\operatorname{GSM}_M(u)=\\lbrace u\\rbrace$ iff $u \\in R$. As a\n    result, $\\operatorname{GSM}_M(L)=L\\cap R$.\n\nA family $\\mathscr{F}$ of languages is said to be closed under GSM\nmappings if for any $L\\in \\mathscr{F}$,\n$\\operatorname{GSM}_M(L)\\in \\mathscr{F}$ for any gsm $M$. Closure under\n$\\lambda$-free GSM mappings and inverse GSM mappings are similarly\ndefined. It can be shown that each of the four families in the Chomsky\nhierarchy is closed under inverse GSM mappings. While the families of\nregular, context-free, and T0 languages are closed under GSM mappings,\nthe family of context-sensitive languages is only closed under\n$\\lambda$-free GSM mappings.\n\n[9]{} A. Salomaa, [*Formal Languages*]{}, Academic Press, New York\n(1973). J.E. Hopcroft, J.D. Ullman, [*Formal Languages and Their\nRelation to Automata*]{}, Addison-Wesley, (1969).",
  "language": "INFORMAL",
  "phrase": "Generalized Sequential Machine",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/GeneralizedSequentialMachine"
    }
  ],
  "indexable": true
}