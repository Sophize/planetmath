{
  "alternatePhrases": [
    "uniform integrability",
    "uniform absolute continuity"
  ],
  "definition": "Let $\\mu$ be a positive measure on a measurable space. A collection of\nfunctions $\\{ f_\\alpha \\} \\subset {\\mathbf{L}}^1(\\mu)$ is [*uniformly\nintegrable*]{}, if for every $\\epsilon > 0$, there exists $\\delta > 0$\nsuch that $$\\begin{aligned}\n{\\Bigl\\lvert \\int_E f_\\alpha \\, d\\mu \\Bigr\\rvert} < \\epsilon \\quad \\textrm{whenever $\\mu(E) < \\delta$, for any $\\alpha$.}\\end{aligned}$$\n\n(The absolute value sign outside of the integral above may appear under\nthe integral sign instead without affecting the definition.)\n\nThe usefulness of this definition comes from the Vitali convergence\ntheorem, which uses it to characterize the convergence of functions in\n${\\mathbf{L}}^1(\\mu)$.\n\nDefinition in probability theory {#definition-in-probability-theory .unnumbered}\n--------------------------------\n\nIn probability , a different, and slightly stronger, definition of\n\u201cuniform integrability\u201d, is more commonly used:\n\nA collection of functions $\\{ f_\\alpha \\} \\subset {\\mathbf{L}}^1(\\mu)$\nis [*uniformly integrable*]{}, if for every $\\epsilon > 0$, there exists\n$t \\geq 0$ such that $$\\begin{aligned}\n\\int_{[{\\lvertf_\\alpha\\rvert} \\geq t]} {\\lvertf_\\alpha\\rvert}  \\, d\\mu < \\epsilon\n\\quad \\textrm{for every $\\alpha$.}\\end{aligned}$$\n\nAssuming $\\mu$ is a probability measure, this definition is equivalent\nto the previous one together with the condition that\n$\\int {\\lvertf_\\alpha\\rvert} \\, d\\mu$ is uniformly bounded for all\n$\\alpha$.\n\nProperties {#properties .unnumbered}\n----------\n\n1.  If a finite number of collections are uniformly integrable, then so\n    is their finite union.\n\n2.  A single $f \\in {\\mathbf{L}}^1(\\mu)$ is always uniformly integrable.\n\n    To see this, observe that $f$ must be almost everywhere\n    non-infinite. Thus $f \\cdot 1_{[ {\\lvertf\\rvert} > k]}$ goes to zero\n    a.e. as $k \\to \\infty$, and it is bounded by ${\\lvertf\\rvert}$. Then\n    $\\int_{[{\\lvertf\\rvert} > k]} {\\lvertf\\rvert}d\\mu \\to 0$ by the\n    dominated convergence theorem. Choosing $k$ big enough so that\n    $\\int_{[{\\lvertf\\rvert} > k]} {\\lvertf\\rvert}d\\mu < \\epsilon$, and\n    letting $\\delta = \\epsilon/k$, we have, when $\\mu(E) < \\delta$,\n    $$\\begin{aligned}\n    \\int_E {\\lvertf\\rvert}d\\mu= \\int_{E \\cap [{\\lvertf\\rvert} \\leq k]} {\\lvertf\\rvert}d\\mu+ \\int_{E \\cap [{\\lvertf\\rvert} > k]} {\\lvertf\\rvert} d\\mu\n    \\leq k \\mu(E) + \\epsilon = 2\\epsilon\\,.\\end{aligned}$$\n\nExamples {#examples .unnumbered}\n--------\n\n1.  If $g$ is an integrable function, then the collection consisting of\n    all measurable functions $f$ dominated by $g$ \u2014 that is,\n    ${\\lvertf\\rvert} \\leq g$ \u2014 is uniformly integrable.\n\n2.  If $X$ is a ${\\mathbf{L}}^1$ random variable on a probability space\n    $\\Omega$, then the set of all of its conditional expectations,\n    $$\\{ {\\mathbb{E}}[X \\mid \\mathcal{G}] \\colon \\mathcal{G}\\text{ is a $\\sigma$-algebra of $\\Omega$} \\}\\,,$$\n    is always uniformly integrable.\n\n3.  If there is an unbounded increasing function\n    $\\phi\\colon [0, \\infty) \\to [0, \\infty)$ such that\n    $$\\int {\\lvertf_\\alpha\\rvert} \\phi({\\lvertf_\\alpha\\rvert}) \\, d\\mu$$\n    is uniformly bounded for all $\\alpha$, then the collection\n    $\\{ f_\\alpha \\}$ is uniformly integrable.\n\n[3]{} Kai Lai Chung. [*A Course in Probability Theory*]{}, third ed.\nAcademic Press, 2001.\n\nGerald B. Folland. [*Real Analysis: Modern Techniques and Their\nApplications*]{}, second ed. Wiley-Interscience, 1999.\n\nJeffrey S. Rosenthal. [*A First Look at Rigorous Probability Theory*]{}.\nWorld Scientific, 2003.",
  "language": "INFORMAL",
  "phrase": "Uniformly Integrable",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/UniformlyIntegrable"
    }
  ],
  "indexable": true
}