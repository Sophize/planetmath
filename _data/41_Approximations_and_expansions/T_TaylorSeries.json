{
  "alternatePhrases": [],
  "definition": "Real Taylor series\n==================\n\nLet $f\\colon I \\to {\\mathbb{R}}$ be a function defined on an open\ninterval $I$, possessing derivatives of all orders at $a \\in I$. Then\nthe power series\n$$T(x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(a)}{k!}(x-a)^k$$ is called\nthe [*Taylor series*]{} for $f$ centered at $a$.\n\nOften the case $a = 0$ is considered, and we have the simpler\n$$T(x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(0)}{k!}x^k\\,,$$ called the\n[*Maclaurin series*]{} for $f$ by some authors.\n\nIf we perform formal term-by-term differentiation of $T(x)$, we find\nthat $T^{(k)}(a) = f^{(k)}(a)$, so it is plausible that $T$ is an\nextrapolation or an approximation to $f$ based on the derivatives of $f$\nat a single point $a$.\n\nIn general, $T$ may not extrapolate or approximate $f$ in the strictest\nsense: a Taylor series does not necessarily converge, and even if it\ndoes, it . It is also not necessarily true that a Taylor series about\n$a$ equals the Taylor series of $f$ about some other point $b$, when\nconsidered as functions.\n\nThose functions whose Taylor series do converge to the function are\ntermed [ *functions*]{}.\n\nIf we start with a *convergent* power series\n$f(x) = c_0 + c_1 (x-a) + c_2 (x-a)^2 + \\dotsb$ to define a function\n$f$, then the Taylor series of $f$ about $a$ will turn out to be the\nsame as our original power series.\n\nTaylor polynomials\n==================\n\nThe $n$th degree [*Taylor polynomial*]{} for $f$ centered at $a$ is the\npolynomial\n$$P_{n,a}(x) = \\sum_{k=0}^{n} \\frac{f^{(k)}(a)}{k!}(x-a)^k \\,.$$ In\ngeneral, $P_{n,a}$ has degree $\\leq n$; it may be $< n$ if some of the\nterms $f^{(k)}(a)$ vanish. Nevertheless, $P_{n,a}$ is characterized by\nthe following properties: it is the unique polynomial of degree $\\leq n$\nwhose derivatives up to the $n$th order at $a$ agree with those of $f$;\nit is also the unique polynomial $p$ of degree $\\leq n$ such that\n$$f(x) - p(x)  = o({\\lvertx-a\\rvert}^n)\\,,  \\quad \\textrm{as $x \\to a$}.$$\n(Landau notation is being used here.) These characterizations are\nsometimes helpful in actually computing Taylor polynomials.\n\nThe Taylor polynomial $P_{n,a}$ is applicable even if $f$ is only\ndifferentiable $n$ times at $a$, or when its Taylor series does not\nconverge to $f$.\n\nThe error from the approximation of $f$ by $P_{n,a}$, or [*remainder\nterm*]{}, $R_{n,a}(x) = f(x) - P_{n,a}(x)$, can be quantified precisely\nusing . In particular, Taylor\u2019s Theorem is often used to show\n$$\\lim_{n\\rightarrow \\infty} R_{n,a}(x) = 0 \\,,$$ which is equivalent to\n$T(x) = f(x)$, i.e. the Taylor series converges to the original\nfunction.\n\nA term that is often heard is that of a \u201cTaylor expansion\u201d; depending on\nthe circumstance, this may mean either the Taylor series or the $n$th\ndegree Taylor polynomial. Both are useful to linearize or otherwise\nreduce the analytical complexity of a function. They are also useful for\nnumerical approximation of functions, when the magnitude of the later\nterms fall off rapidly.\n\nExamples\n========\n\nUsing the above definition of a Taylor series about $0$, we have the\nfollowing important series representations: $$\\begin{aligned}\n e^x &= 1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots \\\\ \n  \\sin x &= \\frac{x}{1!} - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots \\\\\n  \\cos x &= 1-\\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\cdots \\end{aligned}$$\nThat the series on the right converge to the functions on the left can\nbe proven by Taylor\u2019s Theorem.\n\nComplex Taylor series\n=====================\n\nIf $f\\colon U \\to {\\mathbb{C}}$ is a holomorphic function from an open\nsubset $U$ of the complex plane, and $a \\in U$, we may also consider its\nTaylor series about $a$ (defined with the same formulae as before, but\nwith complex numbers).\n\nIn contrast with the complex case, it turns out that all holomorphic\nfunctions are infinitely differentiable and have Taylor series that\nconverge to them. (The radius of convergence of the Taylor series at $a$\nbeing the radius of the largest open disk about $a$ on which the domain\nof $f$ can be extended.)\n\nThis of course makes the theory of analytic functions very nice, and\nmany questions about real power series and real analytic functions are\nmore easily answered by looking at the complex case. For example, we can\nimmediately tell that the Taylor series about the origin for the\n$$\\frac{\\sin z}{\\cos z} = \\tan z = z+\\frac{1}{3} z^3+\\frac{2}{15}z^5+ \\frac{17}{315}z^7+ \\frac{62}{2835} z^9+ \\dotsb$$\nhas a radius of convergence of $\\pi/2$, because $\\tan$ is holomorphic\neverywhere except at its poles at $z = \\pi/2 +k\\pi, k \\in \\mathbb{Z}$,\nand $\\pi/2$ is the distance that the closest of these poles get to the\norigin.\n\nTaylor series and polynomials in Banach spaces\n==============================================\n\nTaylor series and polynomials can be generalized to Banach spaces: for\ndetails, see Taylor\u2019s formula in Banach spaces.\n\nTaylor series and polynomials for functions of several variables\n================================================================\n\nThe simplest Banach spaces are the spaces ${\\mathbb{R}}^n$, and in this\ncase Taylor series and Taylor polynomials for functions\n$f \\colon {\\mathbb{R}}^n \\to {\\mathbb{R}}$ (\u201cfunctions of $n$\nvariables\u201d) look like this: $$\\begin{aligned}\n T(x) &= \\sum_{i_1=0}^\\infty \\cdots \\sum_{i_n=0}^\\infty \n\\frac{f^{(i_1,i_2,\\ldots,i_n)}(0)}{i_1!i_2!\\cdots i_n!}x_1^{i_1}x_2^{i_2} \\cdots x_n^{i_n}\n\\,,\n\\quad\nf^{(i_1,i_2,\\ldots,i_n)}(0) = \\left.\\frac{\\partial^{i_1+\\dotsb+i_n} f}{\\partial x_1^{i_1} \\cdots \\partial x_n^{i_n}}\\right|_{x=0}\\,,\n\\\\\nP_{N,0}(x) &= \\sum_{i_1 + \\dotsb + i_n  \\leq N}\n\\frac{f^{(i_1, i_2, \\ldots, i_n)}(0)}{i_1!i_2!\\cdots i_n!}\n  x_1^{i_1}x_2^{i_2} \\cdots x_n^{i_n}  = \\sum_{{\\lvertI\\rvert} \\leq N} \\frac{1}{I!} \\left.\\frac{\\partial^{{\\lvertI\\rvert}} f}{\\partial x^I}\\right|_{x=0} \\, x^I\\,.\\end{aligned}$$\n(For simplicity, we have put the centre at $a= 0$. The last expression\nemploys a commonly-used multi-index notation.)\n\nFor example, the second-degree Taylor polynomial for\n$f(x,y) = \\cos(x+y)$ centered about $(0,0)$ is\n$$P_{2,0}(x,y) = 1 - \\frac{1}{2} x^2  - xy -   \\frac{1}{2}y^2\\,.$$ Note\nthat $P_{2,0}(x,y)$ can also be obtained by taking the one-variable\nTaylor series $\\cos t = 1 - t^2 / 2 + \\dotsb $ and substituting\n$t = x+y$, and keeping only the terms of degree $\\leq 2$. This procedure\nworks because of the uniqueness characterization of Taylor polynomials.\n\nTaylor expansion of formal polynomials\n======================================\n\nIf $f$ is a polynomial function, of degree $n$, then its Taylor series\nand its Taylor polynomial of degree $\\geq n$ actually equal $f$. For\nthis reason, we can consider Taylor series and polynomials applied to\nformal polynomials, without any notion of convergence. (The usual\nderivative is replaced by formal differentiation.) In this setting, a\n\u201cTaylor expansion\u201d of a formal polynomial $p(x)$ about $a$ amounts to\nnothing more than rewriting $p(x)$ in the form\n$c_0 + c_1 (x-a) + \\dotsb + c_n (x-a)^n$.\n\nSimilar considerations apply to formal power series, or to formal\npolynomials of several variables.\n\n[3]{} Lars V. Ahlfors. [*Complex Analysis*]{}, third edition.\nMcGraw-Hill, 1979. Michael Spivak. [*Calculus*]{}, third edition.\nPublish or Perish, 1994.",
  "language": "INFORMAL",
  "phrase": "Taylor Series",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/TaylorSeries"
    }
  ],
  "indexable": true
}