{
  "argumentText": "1\\) By , we have:\n$$\\Pr\\left\\{ \\sum_{i=1}^{n}\\left( X_{i}-E[X_{i}]\\right) >\\varepsilon \\right\\}\n\\leq \\exp \\left[ -\\sup_{t > 0}\\left( t\\varepsilon -\\psi (t)\\right) \\right]$$\nwhere\n$$\\psi (t)=\\sum_{i=1}^{n}\\left( \\ln E\\left[ e^{tX_{i}}\\right] -tE\\left[ X_{i}%\n\\right] \\right)$$\n\nSince $\\ln x\\leq x-1$ $\\forall x\\geq 0$, $$\\begin{aligned}\n\\psi (t) &=&\\sum_{i=1}^{n}\\left( \\ln E\\left[ e^{tX_{i}}\\right] -tE\\left[\nX_{i}\\right] \\right) \\\\\n&\\leq &\\sum_{i=1}^{n}E\\left[ e^{tX_{i}}\\right] -tE\\left[ X_{i}\\right] -1 \\\\\n&=&\\sum_{i=1}^{n}E\\left[ 1+tX_{i}+\\frac{1}{2}t^{2}X_{i}^{2}+\\sum_{k=3}^{+%\n\\infty }\\frac{t^{k}X_{i}^{k}}{k!}\\right] -tE\\left[ X_{i}\\right] -1 \\\\\n&=&\\sum_{i=1}^{n}\\left( \\frac{1}{2}t^{2}E\\left[ X_{i}^{2}\\right]\n+\\sum_{k=3}^{+\\infty }\\frac{t^{k}E\\left[ X_{i}^{k}\\right] }{k!}\\right) \\\\\n&=&\\frac{1}{2}t^{2}\\sum_{i=1}^{n}E\\left[ X_{i}^{2}\\right] +\\sum_{k=3}^{+%\n\\infty }\\frac{t^{k}\\sum_{i=1}^{n}E\\left[ X_{i}^{k}\\right] }{k!} \\\\\n&\\leq &\\frac{1}{2}t^{2}\\sum_{i=1}^{n}E\\left[ X_{i}^{2}\\right]\n+\\sum_{k=3}^{+\\infty }\\frac{t^{k}\\sum_{i=1}^{n}E\\left[ \\left\\vert\nX_{i}\\right\\vert ^{k}\\right] }{k!},\\end{aligned}$$ and, keeping in mind\nhypotheses a) and b), $$\\begin{aligned}\n\\psi (t) &\\leq &\\frac{1}{2}t^{2}v^2+\\sum_{k=3}^{+\\infty }\\frac{t^{k}}{2}%\nv^2c^{k-2}=\\frac{1}{2}t^{2}v^2+\\frac{1}{2}t^{3}v^2c\\sum_{k=0}^{+\\infty }\\left( tc\\right)^{k}\\end{aligned}$$\n\nNow, if $tc<1$, we obtain\n$$\\psi (t)\\leq \\frac{1}{2}t^{2}v^2\\left( 1+\\frac{tc}{1-tc}\\right) =\\frac{v^2t^{2}}{%\n2\\left( 1-tc\\right) }$$ whence\n$$\\sup_{t > 0}\\left( t\\varepsilon -\\psi (t)\\right) \\geq \\sup_{0 < t < \n\\frac{1}{c}}\\left( t\\varepsilon -\\frac{v^2t^{2}}{2\\left( 1-tc\\right) }\\right)$$\n\nBy elementary calculus, we obtain the value of $t$ that maximizes the\nexpression in brackets (out of the two roots of the second degree\npolynomial equation, we choose the one which is $<\\frac{1}{c}$):\n$$t_{opt}=\\frac{v^2+2c\\varepsilon -v^2\\sqrt{1+\\frac{2c\\varepsilon }{v^2}}}{c\\left(\nv^2+2c\\varepsilon \\right) }=\\frac{1}{c}\\left( 1-\\frac{1}{\\sqrt{1+\\frac{%\n2c\\varepsilon }{v^2}}}\\right)$$ which, once plugged into the bounds,\nyields\n$$\\Pr\\left\\{ \\sum_{i=1}^{n}\\left( X_{i}-E[X_{i}]\\right) >\\varepsilon \\right\\}\n\\leq \\exp \\left[ -\\frac{v^2}{c^{2}}\\left( 1+\\frac{c\\varepsilon }{v^2}-\\sqrt{1+2\n\\frac{c\\varepsilon }{v^2}}\\right) \\right]$$\n\nObserving that $\\sqrt{1+x}\\leq 1+\\frac{1}{2}x$, one gets:\n$$t_{opt}=\\frac{1}{c}\\left( 1-\\frac{1}{\\sqrt{1+\\frac{2c\\varepsilon }{v^2}}}\n\\right) \\leq \\frac{1}{c}\\left( 1-\\frac{1}{1+\\frac{c\\varepsilon }{v^2}}\\right) =%\n\\frac{\\varepsilon }{v^2+c\\varepsilon }=t^{^{\\prime }}<\\frac{1}{c}$$\nPlugging $t^{\\prime }$ in the bound expression, the sub-optimal yet more\neasily manageable formula is obtained:\n$$\\Pr\\left\\{ \\sum_{i=1}^{n}\\left( X_{i}-E[X_{i}]\\right) >\\varepsilon \\right\\}\n\\leq \\exp \\left( -\\frac{\\varepsilon ^{2}}{2\\left( v^2+c\\varepsilon \\right) }%\n\\right)$$ which is obviously a worse bound than the preceeding one,\nsince $t^{\\prime\n}\\neq t_{opt}$. One can also verify the consistency of this inequality\ndirectly proving that, for any $x\\geq 0$,\n$$1+x-\\sqrt{1+2x}\\geq \\frac{x^{2}}{2\\left( 1+x\\right) }$$ (see for an\neasy way, which can be used with $x_0=0$)\n\n2\\) To prove this more specialized statement let\u2019s recall that the\ncondition\n$$\\Pr\\left\\{ \\left\\vert X_{i}\\right\\vert \\leq M\\right\\} =1\\text{ \\ }\\forall i$$\nimplies that, for all $i$,\n$$E[\\left\\vert X_{i}\\right\\vert ^{k}]\\leq M^{k} \\text{ \\ }\\forall k\\geq 0$$\n(See for a proof.)\n\nNow, it\u2019s enough to verify that the condition\n$$E[\\left\\vert X_{i}\\right\\vert ^{k}]\\leq M^{k}$$ imply both conditions\na) and b) in part 1).\n\nIndeed, part a) is obvious, while for part b) one happens to have:\n$$E[\\left\\vert X_{i}\\right\\vert ^{k}]\\leq E\\left[X_{i}^{2}\\right] M^{k-2}$$\n(see for a proof).\n\nSo\n$$\\sum_{i=1}^{n}E[\\left\\vert X_{i}\\right\\vert ^{k}]\\leq \\sum_{i=1}^{n}E\\left[\nX_{i}^{2}\\right] M^{k-2}=v^2M^{k-2}$$\n\nLet\u2019s find a value for $c$ such that\n$v^2M^{k-2}\\leq \\frac{k!}{2}v^2c^{k-2}$, thus satisfying part b) of the\nhypotheses.\n\nAfter simplifying, we have to study the\ninequality$$k!c^{k-2}\\geq 2\\cdot M^{k-2}$$ for any $k\\geq 3$. Let\u2019s\nproceed by induction. For $k=3$, we have$$6c\\geq 2M$$ which suggests\n$c=\\frac{M}{3}$. Let\u2019s now verify if this position is consistent with\nthe inductive\nhypothesis:$$\\left( k+1\\right) !=\\left( k+1\\right) k!\\geq \\left( k+1\\right) \\cdot 2\\cdot\n3^{k-2}\\geq 3\\cdot 2\\cdot 3^{k-2}=2\\cdot 3^{(k+1)-2}$$ which confirms\nthe validity of the choice $c=\\frac{M}{3}$, which has to be plugged into\nthe former bound to obtain the new one.\n\n\\[to be continued...\\]",
  "conclusion": "#P_BernsteinInequalities",
  "language": "INFORMAL",
  "premises": [
    "#P_planetmath_ZFC"
  ],
  "citations": [
    {
      "textCitation": "https://planetmath.org/ProofOfBernsteinInequalities"
    }
  ],
  "indexable": false,
  "names": [
    "proof of Bernstein inequalities"
  ]
}