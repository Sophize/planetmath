{
  "alternatePhrases": [],
  "definition": "Let $\\textbf{X}=(X_1,\\ldots,X_n)$ be a random vector such that\n\n1.  $X_i\\geq 0$ and $X_i\\in\\mathbb{Z}$\n\n2.  $X_1+\\cdots+X_n=N$, where $N$ is a fixed integer\n\nThen $\\textbf{X}$ has a *multinomial distribution* if there exists a\nparameter vector $\\boldsymbol{\\pi}=(\\pi_1,\\ldots,\\pi_n)$ such that\n\n1.  $\\pi_i\\geq 0$ and $\\pi_i\\in\\mathbb{R}$\n\n2.  $\\pi_1+\\cdots+\\pi_n=1$\n\n3.  $\\textbf{X}$ has a discrete probability distribution function\n    $f_{\\textbf{X}}(\\boldsymbol{x})$ in the form:\n    $$f_{\\textbf{X}}(\\boldsymbol{x})=\\frac{N!}{x_1!\\cdots x_n!}\\prod_{i=1}^{n}\\pi_i^{x_i}$$\n\n**Remarks**\n\n-   $\\operatorname{E}[\\textbf{X}]=N\\boldsymbol{\\pi}$\n\n-   $\\operatorname{Var}[\\textbf{X}]=(v_{ij})$, where $$v_{ij}= \n    \\begin{cases}\n    N\\pi_i(1-\\pi_i) & \\text{if $i=j$;}\\\\\n    -N\\pi_i\\pi_j & \\text{if $i\\neq j$.}\n    \\end{cases}$$\n\n-   When $n=2$, the multinomial distribution is the same as the binomial\n    distribution\n\n-   If $X_1,\\ldots,X_n$ are mutually independent Poisson random\n    variables with parameters $\\lambda_1,\\ldots,\\lambda_n$ respectively,\n    then the conditional joint distribution of $X_1,\\ldots,X_n$ given\n    that $X_1+\\cdots+X_n=N$ is multinomial with parameters\n    $\\lambda_i/\\lambda$, where $\\lambda=\\sum\\lambda_i$.\n\n    **Sketch of proof.** Each $X_i$ is distributed as:\n    $$f_{X_i}(x_i) = \\frac{e^{-\\lambda_i} \\lambda_i^{x_i}}{x_i!}$$ The\n    mutual independence of the $X_i$\u2019s shows that the joint probability\n    distribution of the $X_i$\u2019s is given by\n    $$f_{\\textbf{X}}(\\boldsymbol{x})=\\prod_{i=1}^{n}\\frac{e^{-\\lambda_i} \\lambda_i^{x_i}}{x_i!}=\n    e^{-\\lambda}\\prod_{i=1}^{n}\\frac{\\lambda_i^{x_i}}{x_i!},$$ where\n    $\\textbf{X}=(X_1,\\ldots,X_n)$, $\\boldsymbol{x}=\n    (x_1,\\ldots,x_n)$ and $\\lambda=\\lambda_1+\\cdots+\\lambda_n$. Next,\n    let $X=X_1+\\cdots+X_n$. Then $X$ is Poisson distributed with\n    parameter $\\lambda$ (which can be shown by using induction and the\n    mutual independence of the $X_i$\u2019s):\n    $$f_X(x)=\\frac{e^{-\\lambda} \\lambda^{x}}{x!}.$$ The conditional\n    probability distribution of $\\textbf{X}$ given that $X=N$ is thus\n    given by:\n    $$f_{\\textbf{X}}(\\boldsymbol{x}\\mid X=N)=\\frac{f_{\\textbf{X}}(\\boldsymbol{x})}{f_X(N)}=(e^{-\\lambda}\\prod_{i=1}^{n}\\frac{\\lambda_i^{x_i}}{x_i!})/(\\frac{e^{-\\lambda} \\lambda^{N}}{N!})=\\frac{N!}{x_1!\\cdots x_n!}\\prod_{i=1}^{n}(\\frac{\\lambda_i}{\\lambda})^{x_i},$$\n    where $\\sum x_i=N$ and that $\\sum \\lambda_i/\\lambda=1$.",
  "language": "INFORMAL",
  "phrase": "Multinomial Distribution",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/MultinomialDistribution"
    }
  ],
  "indexable": true
}