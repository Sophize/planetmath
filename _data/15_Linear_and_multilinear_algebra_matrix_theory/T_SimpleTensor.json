{
  "alternatePhrases": [
    "tensor rank",
    "entangled"
  ],
  "definition": "The $U \\otimes V$ of two vector spaces $U$ and $V$ is another vector\nspace which is characterised by being universal for bilinear maps on\n$U \\times V$. As part of this package, there is an operation $\\otimes$\non vectors such that ${\\mathbf{u}} \\otimes {\\mathbf{v}} \\in U \\otimes V$\nfor all ${\\mathbf{u}} \\in U$ and ${\\mathbf{v}} \\in V$, and the primary\nsubject of this article is the image of that operation.\n\nThe element ${\\mathbf{w}} \\in U \\otimes V$ is said to be a *simple\ntensor* if there exist ${\\mathbf{u}} \\in U$ and ${\\mathbf{v}} \n  \\in V$ such that ${\\mathbf{w}} = {\\mathbf{u}} \\otimes {\\mathbf{v}}$.\n\nMore generally, the element ${\\mathbf{w}} \\in W = U_1 \\otimes \\dotsb \n  \\otimes U_k$ is said to be a simple tensor (with respect to the\ndecomposition $U_1 \\otimes \\dotsb \\otimes U_k$ of $W$) if there exist\n${\\mathbf{u}}_i \\in U_i$ for $i=1,\\dotsc,k$ such that\n${\\mathbf{w}} = {\\mathbf{u}}_1 \\otimes \\dotsb \\otimes {\\mathbf{u}}_k$.\n\nFor this definition to be interesting, there must also be tensors which\nare not simple, and indeed most tensors aren\u2019t. In order to illustrate\nwhy, it is convenient to consider the tensor product of two\nfinite-dimensional vector spaces $U = {\\mathcal{K}}^m$ and\n$V = {\\mathcal{K}}^n$ over some field ${\\mathcal{K}}$. In this case one\ncan let $U \\otimes V = \n{\\mathcal{K}}^{m \\times n}$ (the vector space of $m \\times n$ matrices),\nsince ${\\mathcal{K}}^{m \\times n}$ is isomorphic to any generic\nconstruction of $U \\otimes V$ and the tensor product of two spaces is\nanyway only defined up to isomorphism. Furthermore considering elements\nof $U$ and $V$ as column vectors, the tensor product of vectors can be\ndefined through\n$${\\mathbf{u}} \\otimes {\\mathbf{v}} = {\\mathbf{u}} \\cdot {\\mathbf{v}}^{\\mathrm{T}}$$\nwhere $\\cdot$ denotes the product of two matrices (in this case an\n$m \\times 1$ matrix by a $1 \\times n$ matrix). As a very concrete\nexample of this,\n$$\\begin{pmatrix} u_1 \\\\ u_2 \\\\ u_3 \\end{pmatrix} \\otimes\n  \\begin{pmatrix} v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4 \\end{pmatrix} =\n  \\begin{pmatrix}\n    u_1v_1 & u_1v_2 & u_1v_3 & u_1v_4 \\\\\n    u_2v_1 & u_2v_2 & u_2v_3 & u_2v_4 \\\\\n    u_3v_1 & u_3v_2 & u_3v_3 & u_3v_4 \n  \\end{pmatrix}\n  \\text{.}$$ One reason the simple tensors in $U \\otimes V$ cannot\nexhaust this space (provded $m,n \\geqslant 2$) is that there are\nessentially only $m+n-1$ degrees of freedom in the choice of a simple\ntensor, but $mn$ in the space $U \\otimes V$ as a whole. Hence\n$${\\mathcal{K}}^m \\otimes {\\mathcal{K}}^n \\neq \n  {   \\left\\{ \\,  {\\mathbf{u}} \\otimes {\\mathbf{v}}  \\,\\,\\vrule\\relax{}\\,\\,  {\\mathbf{u}} \\in {\\mathcal{K}}^m, {\\mathbf{v}} \\in {\\mathcal{K}}^n \\, \\right\\}}\n  \\qquad\\text{when \\(m,n \\geqslant 2\\).}$$\n\nHow can one to understand the non-simple tensors, then? In general, they\nare finite sums of simple tensors. One way to see this is from the\ntheorem that $U \\otimes V$ has a basis consisting of products of pairs\nof basis vectors.\n\nLet $U$ and $V$ be vector spaces over ${\\mathcal{K}}$ with bases\n$\\{{\\mathbf{e}}_i\\}_{i \\in I}$ and $\\{{\\mathbf{f}}_j\\}_{j \\in J}$\nrespectively. Then\n$ \\{ {\\mathbf{e}}_i \\otimes {\\mathbf{f}}_j\\}_{(i,j) \\in \n  I \\times J} $ is a basis for $U \\otimes V$.\n\nExpressing some arbitrary ${\\mathbf{w}} \\in U \\otimes V$ as a linear\ncombination\n$${\\mathbf{w}} = \\sum_{r=1}^n \\lambda_r({\\mathbf{e}}_{i_r} \\otimes {\\mathbf{f}}_{j_r})$$\nwith respect to such a basis immediately produces the decomposition\n$${\\mathbf{w}} = \\sum_{r=1}^n (\\lambda_r{\\mathbf{e}}_{i_r}) \\otimes {\\mathbf{f}}_{j_r}$$\nas a sum of simple tensors, but this decomposition is often far from\noptimally short. Let\n${\\mathbf{e}}_1 = {  \\left(\\begin{smallmatrix}1\\\\0\\end{smallmatrix}\\right)} \\in {\\mathcal{K}}^2$\nand ${\\mathbf{e}}_2 = \n{  \\left(\\begin{smallmatrix}0\\\\1\\end{smallmatrix}\\right)} \\in {\\mathcal{K}}^2$.\nThe tensor ${\\mathbf{e}}_1 \\otimes {\\mathbf{e}}_1 \n+ {\\mathbf{e}}_2 \\otimes {\\mathbf{e}}_2 = {  \\left(\\begin{smallmatrix}1 & 0 \\\\ 0 & 1\\end{smallmatrix}\\right)}$\nis not simple, but as it happens the tensor\n${\\mathbf{e}}_1 \\otimes {\\mathbf{e}}_1 + \n{\\mathbf{e}}_1 \\otimes {\\mathbf{e}}_2 + {\\mathbf{e}}_2 \\otimes {\\mathbf{e}}_1 + \n{\\mathbf{e}}_2 \\otimes {\\mathbf{e}}_2 = {  \\left(\\begin{smallmatrix}1&1\\\\1&1\\end{smallmatrix}\\right)} = \n{  \\left(\\begin{smallmatrix}1\\\\1\\end{smallmatrix}\\right)} \\otimes {  \\left(\\begin{smallmatrix}1\\\\1\\end{smallmatrix}\\right)}$\nis simple. In general it is not trivial to find the simplest way of\nexpressing a tensor as a sum of simple tensors, so there is a name for\nthe length of the shortest such sum.\n\n\\[Def:Rang\\] The *rank* of a tensor ${\\mathbf{w}}$ is the smallest\nnatural number $n$ such that\n${\\mathbf{w}} = {\\mathbf{w}}_1 + \\dotsb + {\\mathbf{w}}_n$ for some set\nof $n$ simple tensors ${\\mathbf{w}}_1$, \u2026, ${\\mathbf{w}}_n$.\n\nIn particular, the zero tensor has rank $0$, and all other simple\ntensors have rank $1$.\n\nThere is an entirely different concept which is also called \u2018the \u2019,\nnamely the number of components (factors) in the tensor product forming\nthe space in which the tensor lives. This latter \u2018rank\u2019 concept does not\ngeneralise \u2018\u2019. The \u2018rank\u2019 of Definition\u00a0\\[Def:Rang\\] *does* generalise\n\u2018rank of a matrix\u2019. (It also generalises .)\n\nOne area where the distinction between simple and non-simple tensors is\nparticularly important is in Quantum Mechanics, because the state space\nof a pair of quantum systems is in general the tensor product of the\nstate spaces of the component systems. When the combined state is a\nsimple tensor ${\\mathbf{w}} = {\\mathbf{u}} \\otimes {\\mathbf{v}}$, then\nthat state can be understood as though one subsystem has state\n${\\mathbf{u}}$ and the other state ${\\mathbf{v}}$, but when the combined\nstate ${\\mathbf{w}}$ is a non-simple tensor\n${\\mathbf{u}}_1 \\otimes {\\mathbf{v}}_1 + \n{\\mathbf{u}}_2 \\otimes {\\mathbf{v}}_2$ then the full system cannot be\nunderstood by considering the two subsystems in isolation, even if there\nis no apparent interaction between them. This situation is often\ndescribed by saying that the two subsystems are *entangled*, or using\nphrases such as \u201ceither $U$ is in state ${\\mathbf{u}}_1$ and $V$ is in\nstate ${\\mathbf{v}}_1$, or else $U$ is in state ${\\mathbf{u}}_2$ and $V$\nis in state ${\\mathbf{v}}_2$.\u201d Entanglement is an important part of that\nwhich makes quantum systems different from probabilistic classical\nsystems. The physical interpretations are often mind-boggling, but the\nmathematical meaning is no more mysterious than \u2018non-simple tensor\u2019.\n\nEntanglement can also be a useful concept for understanding pure\nmathematics. One reason that the comultiplication\n$\\Delta\\colon C {\\longrightarrow}C \\otimes C$ of a coalgebra $C$ cannot\nsimply be replaced in the definition by two maps\n$\\Delta_L,\\Delta_R\\colon C {\\longrightarrow}C$ that compute the \u2018left\u2019\nand \u2018right\u2019 parts of $\\Delta$ is that value of $\\Delta$ may be\nentangled, in which case one left part $\\Delta_L(c)$ and one right part\n$\\Delta_R(c)$ cannot fully encode $\\Delta(c)$.",
  "language": "INFORMAL",
  "phrase": "Simple Tensor",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/SimpleTensor"
    }
  ],
  "indexable": true
}