{
  "argumentText": "First, let\u2019s assume $f$ has a cyclic vector $v$. Then\n$B=\\{v,f(v),...,f^{n-1}(v)\\}$ is a basis for $V$. Suppose $g$ is a\nlinear transformation which commutes with $f$. Consider the coordinates\n$(\\alpha_{0},...,\\alpha_{n-1})$ of $g(v)$ in B, that is\n$$g(v)=\\sum_{i=0}^{n-1}\\alpha_{i}f^{i}(v).$$ Let\n$$P=\\sum_{i=0}^{n-1}\\alpha_{i}X^{i} \\in k[X].$$ We show that $g=P(f)$.\nFor $w \\in V$, write $$w=\\sum_{j=0}^{n-1}\\beta_{j}f^{j}(v),$$ then\n$$\\begin{aligned}\ng(w) &=& \\sum_{j=0}^{n-1}\\beta_{j}g(f^{j}(v)) = \\sum_{j=0}^{n-1}\\beta_{j}f^{j}(g(v)) \\\\\n&=& \\sum_{j=0}^{n-1}\\beta_{j}f^{j}(\\sum_{i=0}^{n-1}\\alpha_{i}f^{i}(v))  \n= \\sum_{j=0}^{n-1}\\beta_{j}\\sum_{i=0}^{n-1}\\alpha_{i}f^{j+i}(v)\n= \\sum_{j=0}^{n-1}\\sum_{i=0}^{n-1}\\beta_{j}\\alpha_{i}f^{j+i}(v) \\\\\n&=& \\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}\\beta_{j}\\alpha_{i}f^{j+i}(v)\n= \\sum_{i=0}^{n-1}\\alpha_{i}f^{i}(\\sum_{j=0}^{n-1}\\beta_{j}f^{j}(v)) \n= \\sum_{i=0}^{n-1}\\alpha_{i}f^{i}(w)\\end{aligned}$$\n\nNow, to finish the proof, suppose $f$ doesn\u2019t have a cyclic vector (we\nwant to see that there is a linear transformation $g$ which commutes\nwith $f$ but is not a polynomial evaluated in $f$). As $f$ doesn\u2019t have\na cyclic vector, then due to the cyclic decomposition theorem $V$ has a\nbasis of the form\n$$B=\\{v_{1}, f(v_{1}),...,f^{j_{1}}(v_{1}),v_{2},f(v_{2}),..., f^{j_{2}}(v_{2}),...,v_{r},f(v_{r}),...,f^{j_{r}}(v_{r})\\}.$$\nLet $g$ be the linear transformation defined in $B$ as follows:\n$$g(f^{k}(v_{1}))= \\left\\{\n\\begin{array}{ll}\n0 & \\textrm{for every } k=0,\\ldots,j_1\\\\\nf^{k_{i}}(v_{i}) & \\textrm{for every } i=2,\\ldots,r\\textrm{ and }k_{i}=0,\\ldots,j_{i}. \n\\end{array}\n\\right.$$ The fact that $f$ and $g$ commute is a consequence of $g$\nbeing defined as zero on one $f$-invariant subspace and as the identity\non its complementary $f$-invariant subspace. Observe that it\u2019s enough to\nsee that $g$ and $f$ commute in the basis $B$ (this fact is trivial). We\nsee that, if $k=0,...,j_{1}-1$, then\n$$(gf)(f^{k}(v_{1}))=g(f^{k+1}(v_{1}))=0\\quad \\mbox{ and }\\quad(fg)(f^{k}(v_{1}))=f(g(f^{k}(v_{1}))=f(0)=0.$$\nIf $k=j_{1}$, we know there are $\\lambda_{0},...,\\lambda_{j_{1}}$ such\nthat $$f^{j_{1}+1}(v_{1})=\\sum_{k=0}^{j_{1}}\\lambda_{k}f^{k}(v_{1}),$$\nso\n$$(gf)(f^{j_{1}}(v_{1}))=\\sum_{k=0}^{j_{1}}\\lambda_{k}g(f^{k}(v_{1}))=0\\quad\\mbox{ and }\\quad(fg)(f^{j_{1}}(v_{1}))=f(0)=0.$$\nNow, let $i=2,...,r$ and $k_{i}=0,...,j_{i}-1$, then\n$$(gf)(f^{k_{i}}(v_{i}))=g(f^{k_{i}+1}(v_{i}))=f^{k_{i}+1}(v_{i})\\quad\\mbox{ and }\\quad (fg)(f^{k_{i}}(v_{i})) =f(g(f^{k_{i}}(v_{i}))= f^{k_{i}+1}(v_{i}).$$\nIn the case $k_{i}=j_{i}$, we know there are\n$\\lambda_{0,i},...,\\lambda_{j_{i},i}$ such that\n$$f^{j_{i}+1}(v_{i})=\\sum_{k=0}^{j_{i}}\\lambda_{k,i}f^{k}(v_{i})$$ then\n$$(gf)(f^{j_{i}}(v_{i}))=g(f^{j_{i}+1}(v_{i}))=\\sum_{k=0}^{j_{i}}\\lambda_{k,i}g(f^{k}(v_{i}))= \\sum_{k=0}^{j_{i}}\\lambda_{k,i}f^{k}(v_{i})=f^{j_{i}+1}(v_{i}),$$\nand\n$$(fg)(f^{j_{i}}(v_{i}))=f(g(f^{j_{i}}(v_{i}))=f(f^{j_{i}}(v_{i}))=f^{j_{i}+1}(v_{i}).$$\nThis proves that $g$ and $f$ commute in $B$. Suppose now that $g$ is a\npolynomial evaluated in $f$. So there is a\n$$P=\\sum_{k=0}^{h}c_{k}X^{k} \\in K[X]$$ such that $g=P(f)$. Then,\n$0=g(v_{1})=P(f)(v_{1})$, and so the annihilator polynomial $m_{v_{1}}$\nof $v_{1}$ divides $P$. But then, as the annihilator $m_{v_{2}}$ of\n$v_{2}$ divides $m_{v_{1}}$ (see the cyclic decomposition theorem), we\nhave that $m_{v_{2}}$ divides $P$, and then\n$0=P(f)(v_{2})=g(v_{2})=v_{2}$ which is absurd because $v_{2}$ is a\nvector of the basis $B$. This finishes the proof.",
  "conclusion": "#P_CyclicVectorTheorem",
  "language": "INFORMAL",
  "premises": [
    "#P_planetmath_ZFC"
  ],
  "citations": [
    {
      "textCitation": "https://planetmath.org/ProofOfCyclicVectorTheorem"
    }
  ],
  "indexable": false,
  "names": [
    "proof of cyclic vector theorem"
  ]
}