{
  "language": "INFORMAL",
  "remarks": "",
  "statement": "Let ${\\mathbf{M}}= (M_{ij})$ be an $n\\times n$ matrix with entries in a\nfield $K$. The matrix ${\\mathbf{M}}$ is really the same thing as a list\nof $n$ column vectors of size $n$. Consequently, the determinant\noperation may be regarded as a mapping\n$$\\det:\\overbrace{K^n\\times\\ldots\\times K^n}^{n \\mbox{\n    times}}\\rightarrow K$$ The determinant of a matrix ${\\mathbf{M}}$ is\nthen defined to be $\\det({\\mathbf{M}}_1,\\ldots,{\\mathbf{M}}_n),$ where\n${\\mathbf{M}}_j\\in K^n$ denotes the $j{^{\\text{th}}}$ column of\n${\\mathbf{M}}$.\n\nStarting with the definition $$\\label{eq:detdef}\n\\det({\\mathbf{M}}_1,\\ldots,{\\mathbf{M}}_n) = \\sum_{\\pi\\in S_n} \\mathrm{sgn}(\\pi) M_{1\\pi_1}\nM_{2\\pi_2}\\cdots  \nM_{n\\pi_n}$$ the following properties are easily established:\n\n1.  the determinant is multilinear;\n\n2.  the determinant is anti-symmetric;\n\n3.  the determinant of the identity matrix is $1$.\n\nThese three properties uniquely characterize the determinant, and indeed\ncan \u2014 some would say should \u2014 be used as the definition of the\ndeterminant operation.\n\nLet us prove this. We proceed by representing elements of $K^n$ as\nlinear combinations of\n$${\\mathbf{e}}_1=\\begin{pmatrix} 1\\\\0\\\\0\\\\\\vdots\\\\0\\end{pmatrix},\\quad\n{\\mathbf{e}}_2=\\begin{pmatrix} 0\\\\1\\\\0\\\\\\vdots\\\\0\\end{pmatrix},\\quad \\ldots\\quad\n{\\mathbf{e}}_n=\\begin{pmatrix} 0\\\\0\\\\0\\\\ \\vdots\\\\1\\end{pmatrix},$$ the\nstandard basis of $K^n$. Let ${\\mathbf{M}}$ be an $n\\times n$ matrix.\nThe $j{^{\\text{th}}}$ column is represented as\n$\\sum_i M_{ij}{\\mathbf{e}}_i$; whence using multilinearity\n$$\\begin{aligned}\n\\det({\\mathbf{M}}) &= \\det{\\left(}\\sum_i M_{i1}{\\mathbf{e}}_i\\,,\\sum_i\nM_{i2}{\\mathbf{e}}_i\\,,\\;\\ldots\\;,\\sum_i M_{in} {\\mathbf{e}}_i{\\right)}\\\\  \n&=\\sum_{i_1,\\ldots,i_n=1}^n M_{i_11} M_{i_22} \\cdots M_{i_n n} \n\\det({\\mathbf{e}}_{i_1},{\\mathbf{e}}_{i_2},\\ldots,{\\mathbf{e}}_{i_n})\\end{aligned}$$\nThe anti-symmetry assumption implies that the expressions\n$\\det({\\mathbf{e}}_{i_1},{\\mathbf{e}}_{i_2},\\ldots,{\\mathbf{e}}_{i_n})$\nvanish if any two of the indices $i_1,\\ldots,i_n$ coincide. If all $n$\nindices are distinct,\n$$\\det({\\mathbf{e}}_{i_1},{\\mathbf{e}}_{i_2},\\ldots,{\\mathbf{e}}_{i_n}) = \\pm\n\\det({\\mathbf{e}}_1,\\ldots,{\\mathbf{e}}_n),$$ the sign in the above\nexpression being determined by the number of transpositions required to\nrearrange the list $(i_1,\\ldots,i_n)$ into the list $(1,\\ldots,n)$. The\nsign is therefore the parity of the permutation $(i_1,\\ldots,i_n)$.\nSince we also assume that\n$$\\det({\\mathbf{e}}_1,\\ldots,{\\mathbf{e}}_n)=1,$$ we now recover the\noriginal definition .",
  "citations": [
    {
      "textCitation": "https://planetmath.org/DeterminantAsAMultilinearMapping"
    }
  ],
  "indexable": true,
  "names": [
    "determinant as a multilinear mapping"
  ]
}