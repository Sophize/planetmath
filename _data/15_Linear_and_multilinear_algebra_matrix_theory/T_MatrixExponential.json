{
  "alternatePhrases": [],
  "definition": "The *exponential* of a real valued square matrix $A$, denoted by $e^A$,\nis defined as $$\\begin{aligned}\ne^A &=& \\sum_{k=0}^\\infty \\frac{1}{k!}A^k \\\\\n    &=& I + A + \\frac{1}{2} A^2 + \\cdots\\end{aligned}$$ Let us check\nthat $e^A$ is a real valued square matrix. Suppose $M$ is a real number\nsuch $|A_{ij}| < M$ for all entries $A_{ij}$ of $A$. Then\n$|(A^2)_{ij}| < nM^2$ for all entries in $A^2$, where $n$ is the order\nof $A$. (Alternatively, one could argue using matrix norms: We have\n$||e^A||\\leq e^{||A||}$ for the 2-norm, and hence the entries of $e^A$\nare bounded by $M=||e^A||$.) Thus, in general, we have\n$|(A^k)_{i,j}| < n^k M^{k+1}$. Since\n$\\sum_{k=0}^\\infty \\frac{n^k}{k!} M^{k+1}$ converges, we see that $e^A$\nconverges to real valued $n\\times n$ matrix.\n\n[**Example 1.**]{} Suppose $A$ is nilpotent, i.e., $A^r = 0$ for some\nnatural number $r$. Then $$\\begin{aligned}\ne^A &=& I + A + \\frac{1}{2!} A^2 + \\cdots + \\frac{1}{(r-1)!} A^{r-1}. \\end{aligned}$$\n\n[**Example 2.**]{} If $A$ is diagonalizable, i.e., of the form\n$A=L D L^{-1}$, where $D$ is a diagonal matrix, then $$\\begin{aligned}\ne^A &=& \\sum_{k=0}^\\infty \\frac{1}{k!}(LDL^{-1})^k \\\\\n &=& \\sum_{k=0}^\\infty \\frac{1}{k!}LD^kL^{-1} \\\\ \n    &=& L e^D L^{-1}.\\end{aligned}$$ Further, if\n$D={\\mathop{\\mathrm{diag}}}\\{a_1,\\cdots, a_n\\}$, then\n$D^k = {\\mathop{\\mathrm{diag}}}\\{a_1^k, \\cdots, a_n^k\\}$ whence\n$$\\begin{aligned}\ne^A &=& L {\\mathop{\\mathrm{diag}}}\\{e^{a_1}, \\cdots, e^{a_n}\\} L^{-1}.\\end{aligned}$$\nFor diagonalizable matrix $A$, it follows that\n$\\det e^A = e^{{\\mathop{\\mathrm{tr}}}A}$. However, this formula is, in\nfact, valid for all $A$.\n\n[****]{}\\\nLet $A$ be a square $n\\times n$ real valued matrix. Then the matrix\nexponential satisfies the following properties\n\n1.  For the $n\\times n$ zero matrix $O$, $e^O=I$, where $I$ is the\n    $n\\times n$ identity matrix.\n\n2.  If $A=L{\\mathop{\\mathrm{diag}}}\\{a_1,\\cdots, a_n\\} L^{-1}$ for an\n    invertible $n\\times n$ matrix $L$, then\n    $$e^A = L {\\mathop{\\mathrm{diag}}}\\{e^{a_1},\\cdots, e^{a_n}\\} L^{-1}.$$\n\n3.  If $A$ and $B$ commute, then $e^{A+B} = e^{A} e^B$.\n\n4.  The trace of $A$ and the determinant of $e^A$ are related by the\n    formula $$\\det e^A = e^{{\\mathop{\\mathrm{tr}}}A}.$$ In effect, $e^A$\n    is always invertible. The inverse is given by\n    $$(e^A)^{-1} = e^{-A}.$$\n\n5.  If $e^A$ is a rotational matrix, then ${\\mathop{\\mathrm{tr}}}A=0$.\n\n[**A relevant example on property 3.**]{}\\\nWe report an interesting example where the cited property is valid. In\nthe field of complex numbers consider the complex matrix $$C = A + iB,$$\nbeing $C$ hermitian, i.e. $C^\\intercal = \\bar{C}$ (here \u201c$\\intercal$\u201d\nand overline \u201c$-$\u201d stand for tranposition and conjugation, respectively)\nand orthogonal, i.e $C^{-1} = C^\\intercal$ . From (1),\n$$C^\\intercal = A^\\intercal + iB^\\intercal.$$ Since $C$ is orthogonal,\nfrom the complex equation $CC^\\intercal = I$ ($I$ is the identity\nmatrix), we have\n$$CC^\\intercal = (A + iB)(A^\\intercal + iB^\\intercal) = (AA^\\intercal - BB^\\intercal) + i(BA^\\intercal + AB^\\intercal) = I,$$\nwhence the imaginary part leads to the equation\n$$BA^\\intercal + AB^\\intercal = 0.$$ But $C$ is also hermitian, so that\n$$C^\\intercal = A^\\intercal + iB^\\intercal = \\bar{C} = A - iB,$$\ntherefore $A^\\intercal = A$ is symmetric, and $B^\\intercal = -B$ is\nskew-symmetric. From these and (2), $BA = AB$, and this implies that\n$\\exp(A)\\cdot \\exp(B) = \\exp(A + B)$. So that, the real and imaginary\nparts of an orthogonal and hermitian matrix verifies the property.\nLikewise, it is easy to show that if the complex matrix is symmetric and\nunitary, its real an imaginary components also verify this property.",
  "language": "INFORMAL",
  "phrase": "Matrix Exponential",
  "remarks": "",
  "citations": [
    {
      "textCitation": "https://planetmath.org/MatrixExponential"
    }
  ],
  "indexable": true
}