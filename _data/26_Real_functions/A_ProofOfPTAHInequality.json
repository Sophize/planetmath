{
  "argumentText": "In order to prove the PTAH inequality two lemmas are needed. The first\nlemma is quite general and does not depend on the specific $P$ and $Q$\nthat are defined for the PTAH inequality.\n\nThe setup for the first lemma is as follows:\n\nWe still have a measure space $X$ with measure $m$. We have a subset\n$\\Lambda \\subseteq {\\mathbb{R}}^{n}$. And we have a function\n$p: X \\times \\Lambda \\to \\mathbb{R}$ which is positive and is integrable\nin $x$ for all $\\lambda \\in \\Lambda$. Also,\n$p(x,\\lambda )\\log p(x, \\lambda')$ is integrable in $x$ for each pair\n$\\lambda, \\lambda' \\in \\Lambda$.\n\nDefine $P: \\Lambda \\to \\mathbb{R}$ by\n\n$$P(\\lambda ) = \\int p(x,\\lambda ) dm(x)$$\n\nand $Q: \\Lambda \\times \\Lambda \\to \\mathbb{R}$\n\nby\n$$Q(\\lambda, \\lambda' ) = \\int p(x,\\lambda ) \\log p(x, \\lambda') dm(x).$$\n\n**Lemma 1** (1)\n$P(\\lambda ) \\log \\frac{P(\\lambda')}{P(\\lambda)} \\ge Q(\\lambda , \\lambda' ) - Q(\\lambda, \\lambda) $\n(2) if $Q(\\lambda , \\lambda') \\ge Q(\\lambda , \\lambda) $ then\n$P(\\lambda') \\ge P(\\lambda)$. If equality holds then\n$p(x,\\lambda) = p(x,\\lambda')$ a.e \\[m\\].\n\n**Proof** It is clear that (2) follows from (1), so we only need to\nprove (1). Define a measure\n$d\\nu(x) = \\frac{p(x,\\lambda)dm(x)}{P(\\lambda)}$. Then\n$$\\int d\\nu(x) = 1$$ so we can use Jensen\u2019s inequality for the\nlogarithm.\n\n$$\\begin{aligned}\nQ(\\lambda, \\lambda')- Q(\\lambda , \\lambda ) &=& \\int p(x,\\lambda )[\\log p(x, \\lambda' ) - \\log p(x, \\lambda ) ] dm(x) \\\\\n&=& \\int p(x,\\lambda ) \\log \\frac{p(x,\\lambda')}{p(x,\\lambda)} dm(x) \\\\\n& =& P(\\lambda) \\int \\log \\frac{p(x,\\lambda')}{p(x,\\lambda)} d\\nu(x) \\\\\n& \\le& P(\\lambda) \\log \\int \\frac{p(x,\\lambda')}{p(x,\\lambda)} d\\nu(x) \\\\\n& =& P(\\lambda ) \\log \\int \\frac{p(x, \\lambda')}{P(\\lambda)} dm(x) \\\\\n& =& P(\\lambda) \\log \\frac{P(\\lambda')}{P(\\lambda)}.\\end{aligned}$$\n\nThe next lemma uses the notation of the parent entry.\n\n**Lemma 2** Suppose $r_i \\ge 0$ for $i=1, \\ldots, n$ and\n$\\theta = (\\theta_1, \\ldots, \\theta_n ) \\in \\sigma$. If $\\sum_j r_j > 0$\nthen\n$$\\prod_{i=1}^{n} {\\theta_i}^{r_i} \\le \\prod_i ( \\frac{r_i}{\\sum_j r_j})^{r_i}.$$\n\n**Proof.** Let $\\lambda = (\\lambda_i) \\in \\sigma$. By the concavity of\nthe $\\log$ function we have\n\n$$\\sum_i \\lambda_i \\log x_i \\le \\log \\sum_i \\lambda_i x_i$$ where\n$x_i > 0$ for $\\i=1, \\ldots, n$.\n\nso that\n$$\\prod_i {x_i}^{\\lambda_i} \\le \\sum_i \\lambda_i x_i = \\prod_i ( \\sum_j \\lambda_j x_j )^{\\lambda_i} .$$\n\nIt is enough to prove the lemma for the case where $r_i>0$ for all $i$.\nWe can also assume $\\theta_i > 0$ for all $i$, otherwise the result is\ntrivial.\n\nLet $\\rho = \\sum_j r_j > 0$ and $\\lambda_i = \\frac{r_i}{\\rho}$ so that\n$\\rho \\lambda_i = r_i$.\n\nRaise each side of (1) to the $\\rho$ power:\n\n$$\\prod_i {x_i}^{r_i} \\le \\prod_i (\\sum_j \\lambda_j x_j )^{r_i}$$\n\nso that $$\\prod_i (\\frac{x_i}{\\sum_j \\lambda_j x_j })^{r_i} \\le 1$$\nMultiply (3) by $\\prod (\\frac{r_i}{\\rho})^{r_i}$ to get:\n\n$$\\prod_i ( \\frac{r_i x_i}{\\sum_j r_j x_j})^{r_i} \\le \\prod_i (r_i/\\rho)^{r_i}.$$\n\nClaim: There exist $x_i>0 $, $i=1,\\ldots, n$ such that\n$$\\theta_i = \\frac{r_i x_i}{\\sum_j r_j x_j}.$$ If so, then substituting\ninto (4)\n$$\\prod_i {\\theta_i}^{r_i} \\le \\prod_i ( \\frac{r_i}{\\rho})^{r_i} = \\prod_i (\\frac{r_i}{\\sum_j r_j})^{r_i}$$\n\nSo it remains to prove the claim. We have to solve the system of\nequations $\\theta_i \\sum_j r_j x_j = r_i x_i$, $i=1, \\ldots, n$ for\n$x_i$. Rewriting this in matrix form, let $A=(a_{ij})$,\n$R=\\textrm{diag}(r_1, \\ldots, r_n)$, and\n$x=\\textrm{diag}(x_1, \\ldots, x_n)$, where $a_{ii} = \\theta_i-1$ and\n$a_{ij} = \\theta_i$ if $i \\not = j$, $i,j=1,\\ldots, n$. The columns sums\nof $A$ are $0$, since $\\theta \\in \\sigma$. Hence $A$ is singular and the\nhomogenous system $ARx=0$ has a nonzero solution, say $x$. Since $R$ is\nnonsingular, it follows that $Rx \\not = 0$. It follows that\n$r_i x_i \\not = 0$ for some $i$ and therefore $\\sum_j r_j x_j \\not = 0$.\nIf necessary, we can replace $x$ by $-x$ so that $\\sum_j r_j x_j >0$.\nFrom (5) it follows that $x_j >0$ for all $j$.\n\nNow we can prove the PTAH inequality. Let\n$r_i(\\lambda) = \\int a_i(x) \\prod_j {\\lambda_j}^{a_j(x)} dm(x)$.\n\nWe calculate $\\frac{\\partial P}{\\partial \\lambda_i}$ by differentiating\nunder the integral sign. If $\\lambda_i>0$ then\n$$\\frac{\\partial P}{\\partial \\lambda_i} = r_i(\\lambda)/\\lambda_i .$$\nThus $$\\lambda_i \\frac{\\partial P}{\\partial \\lambda_i} = r_i(\\lambda).$$\nIf $\\lambda_i =0$ then by writing\n$$r_i(\\lambda) = \\int_E a_i(x) \\ldots dm(x) + \\int_{E^c} {\\lambda_i}^{a_i(x)} \\ldots dm(x)$$\nwhere $E = \\{x \\in X | a_i(x) =0\\}$ it is clear that each integral is 0,\nso that $r_i(\\lambda) =0$. So again, (6) holds. Therefore,\n$$\\frac{r_i(\\lambda)}{\\sum_j r_j (\\lambda)} =  \\frac{\\lambda_i \\partial P/\\partial \\lambda_i }{\\sum_j \\lambda_j \\partial P/\\lambda_j} = \\overline{\\lambda_i}.$$\n\nThen $$\\begin{aligned}\nQ(\\lambda, \\lambda') &=& \\int  \\prod_j {\\lambda_j}^{a_j(x)} \\log \\prod_i ( {\\lambda_i}')^{a_i(x)} dm(x)\\\\\n& =&\\sum_i \\log {\\lambda_i}' \\int a_i(x) \\prod_j {\\lambda_j}^{a_j(x)} dm(x) \\\\\n&=& \\sum_i r_i(\\lambda) \\log {\\lambda_i}' \\\\\n&=& \\log \\prod_i ({\\lambda_i}')^{r_i(\\lambda)} \\\\\n& \\le&\\log \\prod_i ( \\frac{r_i(\\lambda)}{\\sum_j r_j(\\lambda)})^{r_i(\\lambda)} \\\\\n& =& \\log \\prod_i ({\\overline{\\lambda_i}})^{ r_i(\\lambda) }\\\\\n& =& Q(\\lambda , \\overline{\\lambda}).\\end{aligned}$$\n\nNow by Lemma 1, with $\\overline{\\lambda} = \\lambda'$ we get\n$P(\\overline{\\lambda}) \\ge P(\\lambda)$.",
  "conclusion": "#P_PTAHInequality",
  "language": "INFORMAL",
  "premises": [
    "#P_planetmath_ZFC"
  ],
  "citations": [
    {
      "textCitation": "https://planetmath.org/ProofOfPTAHInequality"
    }
  ],
  "indexable": false,
  "names": [
    "proof  of PTAH inequality"
  ]
}